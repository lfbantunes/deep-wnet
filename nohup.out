2019-01-23 20:14:02.273373: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-01-23 20:14:02.345456: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:964] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-01-23 20:14:02.345845: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:01:00.0
totalMemory: 11.91GiB freeMemory: 9.72GiB
2019-01-23 20:14:02.345858: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-01-23 20:14:02.616033: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-01-23 20:14:02.616064: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-01-23 20:14:02.616069: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-01-23 20:14:02.616242: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 9392 MB memory) -> physical GPU (device: 0, name: TITAN Xp, pci bus id: 0000:01:00.0, compute capability: 6.1)
2019-01-23 20:14:13.307018: W tensorflow/core/common_runtime/bfc_allocator.cc:211] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.31GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2019-01-23 20:14:13.341522: W tensorflow/core/common_runtime/bfc_allocator.cc:211] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.65GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2019-01-23 20:14:13.391511: W tensorflow/core/common_runtime/bfc_allocator.cc:211] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.87GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2019-01-23 20:14:13.412601: W tensorflow/core/common_runtime/bfc_allocator.cc:211] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.58GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2019-01-23 20:14:13.457480: W tensorflow/core/common_runtime/bfc_allocator.cc:211] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.45GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2019-01-23 20:14:13.478039: W tensorflow/core/common_runtime/bfc_allocator.cc:211] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.37GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2019-01-23 20:14:13.541734: W tensorflow/core/common_runtime/bfc_allocator.cc:211] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.08GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2019-01-23 20:14:13.564366: W tensorflow/core/common_runtime/bfc_allocator.cc:211] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.54GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2019-01-23 20:14:13.647867: W tensorflow/core/common_runtime/bfc_allocator.cc:211] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.06GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2019-01-23 20:14:13.752249: W tensorflow/core/common_runtime/bfc_allocator.cc:211] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.15GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
Reading images
01 read
02 read
03 read
04 read
05 read
06 read
07 read
08 read
09 read
10 read
11 read
12 read
13 read
14 read
15 read
16 read
17 read
18 read
19 read
20 read
21 read
22 read
23 read
24 read
Images were read
start train net
Generated 4000 patches
Generated 1000 patches
Train on 4000 samples, validate on 1000 samples
Epoch 1/150
 - 39s - loss: 0.0780 - val_loss: 0.0870
Epoch 2/150
 - 34s - loss: 0.0730 - val_loss: 0.0834
Epoch 3/150
 - 34s - loss: 0.0728 - val_loss: 0.0843
Epoch 4/150
 - 34s - loss: 0.0727 - val_loss: 0.0968
Epoch 5/150
 - 34s - loss: 0.0705 - val_loss: 0.0953
from: can't read /var/mail/unet_model
from: can't read /var/mail/gen_patches
import-im6.q16: unable to open X server `' @ error/import.c/ImportImageCommand/358.
import-im6.q16: unable to open X server `' @ error/import.c/ImportImageCommand/358.
import-im6.q16: unable to open X server `' @ error/import.c/ImportImageCommand/358.
from: can't read /var/mail/keras.callbacks
from: can't read /var/mail/keras.callbacks
from: can't read /var/mail/keras.callbacks
/home/mdias/deep-unet-for-satellite-image-segmentation/train_unet.py: 12: /home/mdias/deep-unet-for-satellite-image-segmentation/train_unet.py: Syntax error: "(" unexpected
2019-01-23 20:20:46.726015: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-01-23 20:20:46.795134: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:964] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-01-23 20:20:46.795644: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:01:00.0
totalMemory: 11.91GiB freeMemory: 9.72GiB
2019-01-23 20:20:46.795662: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-01-23 20:20:47.071208: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-01-23 20:20:47.071239: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-01-23 20:20:47.071244: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-01-23 20:20:47.071408: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 9392 MB memory) -> physical GPU (device: 0, name: TITAN Xp, pci bus id: 0000:01:00.0, compute capability: 6.1)
2019-01-23 20:20:57.355383: W tensorflow/core/common_runtime/bfc_allocator.cc:211] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.31GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2019-01-23 20:20:57.388889: W tensorflow/core/common_runtime/bfc_allocator.cc:211] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.65GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2019-01-23 20:20:57.436295: W tensorflow/core/common_runtime/bfc_allocator.cc:211] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.87GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2019-01-23 20:20:57.457305: W tensorflow/core/common_runtime/bfc_allocator.cc:211] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.58GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2019-01-23 20:20:57.500034: W tensorflow/core/common_runtime/bfc_allocator.cc:211] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.45GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2019-01-23 20:20:57.516327: W tensorflow/core/common_runtime/bfc_allocator.cc:211] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.37GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2019-01-23 20:20:57.573449: W tensorflow/core/common_runtime/bfc_allocator.cc:211] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.08GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2019-01-23 20:20:57.595344: W tensorflow/core/common_runtime/bfc_allocator.cc:211] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.54GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2019-01-23 20:20:57.676715: W tensorflow/core/common_runtime/bfc_allocator.cc:211] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.06GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2019-01-23 20:20:57.780463: W tensorflow/core/common_runtime/bfc_allocator.cc:211] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.15GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
Reading images
01 read
02 read
03 read
04 read
05 read
06 read
07 read
08 read
09 read
10 read
11 read
12 read
13 read
14 read
15 read
16 read
17 read
18 read
19 read
20 read
21 read
22 read
23 read
24 read
Images were read
start train net
Generated 4000 patches
Generated 1000 patches
Train on 4000 samples, validate on 1000 samples
Epoch 1/150
 - 40s - loss: 0.0745 - val_loss: 0.0874
Epoch 2/150
 - 35s - loss: 0.0721 - val_loss: 0.1425
Epoch 3/150
 - 35s - loss: 0.0720 - val_loss: 0.1061
Epoch 4/150
 - 35s - loss: 0.0696 - val_loss: 0.1042
Epoch 5/150
 - 35s - loss: 0.0725 - val_loss: 0.2333
Epoch 6/150
 - 35s - loss: 0.0697 - val_loss: 0.1033
Epoch 7/150
 - 35s - loss: 0.0668 - val_loss: 0.1197
Epoch 8/150
 - 35s - loss: 0.0653 - val_loss: 0.0942
Epoch 9/150
 - 35s - loss: 0.0659 - val_loss: 0.0977
Epoch 10/150
 - 35s - loss: 0.0644 - val_loss: 0.0902
Epoch 11/150
 - 35s - loss: 0.0655 - val_loss: 0.0943
Epoch 12/150
 - 35s - loss: 0.0650 - val_loss: 0.0828
Epoch 13/150
 - 35s - loss: 0.0642 - val_loss: 0.0926
Epoch 14/150
 - 35s - loss: 0.0643 - val_loss: 0.0954
Epoch 15/150
 - 35s - loss: 0.0627 - val_loss: 0.0979
Epoch 16/150
 - 35s - loss: 0.0614 - val_loss: 0.0833
Epoch 17/150
 - 35s - loss: 0.0618 - val_loss: 0.0797
Epoch 18/150
 - 35s - loss: 0.0615 - val_loss: 0.0871
Epoch 19/150
 - 35s - loss: 0.0604 - val_loss: 0.0822
Epoch 20/150
 - 35s - loss: 0.0614 - val_loss: 0.1221
Epoch 21/150
 - 35s - loss: 0.0616 - val_loss: 0.0987
Epoch 22/150
 - 35s - loss: 0.0627 - val_loss: 0.1224
Epoch 23/150
 - 35s - loss: 0.0608 - val_loss: 0.0775
Epoch 24/150
 - 35s - loss: 0.0586 - val_loss: 0.0851
Epoch 25/150
 - 35s - loss: 0.0584 - val_loss: 0.0873
Epoch 26/150
 - 35s - loss: 0.0576 - val_loss: 0.0969
Epoch 27/150
 - 35s - loss: 0.0576 - val_loss: 0.1080
Epoch 28/150
 - 35s - loss: 0.0592 - val_loss: 0.1021
Epoch 29/150
 - 35s - loss: 0.0579 - val_loss: 0.0791
Epoch 30/150
 - 35s - loss: 0.0574 - val_loss: 0.0945
Epoch 31/150
 - 35s - loss: 0.0572 - val_loss: 0.1239
Epoch 32/150
 - 35s - loss: 0.0572 - val_loss: 0.0917
Epoch 33/150
 - 35s - loss: 0.0582 - val_loss: 0.0806
Epoch 34/150
 - 35s - loss: 0.0566 - val_loss: 0.0949
Epoch 35/150
 - 35s - loss: 0.0557 - val_loss: 0.0837
Epoch 36/150
 - 35s - loss: 0.0560 - val_loss: 0.1011
Epoch 37/150
 - 35s - loss: 0.0543 - val_loss: 0.0970
Epoch 38/150
 - 35s - loss: 0.0538 - val_loss: 0.0831
Epoch 39/150
 - 35s - loss: 0.0538 - val_loss: 0.0928
Epoch 40/150
 - 35s - loss: 0.0547 - val_loss: 0.0867
Epoch 41/150
 - 35s - loss: 0.0538 - val_loss: 0.1078
Epoch 42/150
 - 35s - loss: 0.0543 - val_loss: 0.0767
Epoch 43/150
 - 35s - loss: 0.0532 - val_loss: 0.0864
Epoch 44/150
 - 35s - loss: 0.0529 - val_loss: 0.0798
Epoch 45/150
 - 35s - loss: 0.0540 - val_loss: 0.0839
Epoch 46/150
 - 35s - loss: 0.0526 - val_loss: 0.0987
Epoch 47/150
 - 35s - loss: 0.0516 - val_loss: 0.1217
Epoch 48/150
 - 35s - loss: 0.0514 - val_loss: 0.0877
Epoch 49/150
 - 35s - loss: 0.0524 - val_loss: 0.0864
Epoch 50/150
 - 35s - loss: 0.0517 - val_loss: 0.0822
Epoch 51/150
 - 35s - loss: 0.0513 - val_loss: 0.0785
Epoch 52/150
 - 35s - loss: 0.0518 - val_loss: 0.1299
Epoch 53/150
 - 35s - loss: 0.0539 - val_loss: 0.0878
Epoch 54/150
 - 35s - loss: 0.0515 - val_loss: 0.0786
Epoch 55/150
 - 35s - loss: 0.0503 - val_loss: 0.0775
Epoch 56/150
 - 35s - loss: 0.0497 - val_loss: 0.0849
Epoch 57/150
 - 35s - loss: 0.0491 - val_loss: 0.0789
Epoch 58/150
 - 35s - loss: 0.0489 - val_loss: 0.0823
Epoch 59/150
 - 35s - loss: 0.0527 - val_loss: 0.1191
Epoch 60/150
 - 35s - loss: 0.0509 - val_loss: 0.0936
Epoch 61/150
 - 35s - loss: 0.0496 - val_loss: 0.0757
Epoch 62/150
 - 35s - loss: 0.0483 - val_loss: 0.0836
Epoch 63/150
 - 35s - loss: 0.0479 - val_loss: 0.0789
Epoch 64/150
 - 35s - loss: 0.0473 - val_loss: 0.0856
Epoch 65/150
 - 35s - loss: 0.0474 - val_loss: 0.0794
Epoch 66/150
 - 35s - loss: 0.0474 - val_loss: 0.1283
Epoch 67/150
 - 35s - loss: 0.0484 - val_loss: 0.0830
Epoch 68/150
 - 35s - loss: 0.0471 - val_loss: 0.0857
Epoch 69/150
 - 35s - loss: 0.0475 - val_loss: 0.0832
Epoch 70/150
 - 35s - loss: 0.0462 - val_loss: 0.0827
Epoch 71/150
 - 35s - loss: 0.0460 - val_loss: 0.0761
Epoch 72/150
 - 35s - loss: 0.0461 - val_loss: 0.0832
Epoch 73/150
 - 35s - loss: 0.0458 - val_loss: 0.0835
Epoch 74/150
 - 35s - loss: 0.0450 - val_loss: 0.0842
Epoch 75/150
 - 35s - loss: 0.0455 - val_loss: 0.0840
Epoch 76/150
 - 35s - loss: 0.0447 - val_loss: 0.0776
Epoch 77/150
 - 35s - loss: 0.0444 - val_loss: 0.0848
Epoch 78/150
 - 35s - loss: 0.0447 - val_loss: 0.0892
Epoch 79/150
 - 35s - loss: 0.0443 - val_loss: 0.0927
Epoch 80/150
 - 35s - loss: 0.0451 - val_loss: 0.0960
Epoch 81/150
 - 35s - loss: 0.0448 - val_loss: 0.0933
Epoch 82/150
 - 35s - loss: 0.0481 - val_loss: 0.1051
Epoch 83/150
 - 35s - loss: 0.0452 - val_loss: 0.0880
Epoch 84/150
 - 35s - loss: 0.0441 - val_loss: 0.0813
Epoch 85/150
 - 35s - loss: 0.0442 - val_loss: 0.0875
Epoch 86/150
 - 35s - loss: 0.0431 - val_loss: 0.0798
Epoch 87/150
 - 35s - loss: 0.0427 - val_loss: 0.0852
Epoch 88/150
 - 35s - loss: 0.0425 - val_loss: 0.0867
Epoch 89/150
 - 35s - loss: 0.0424 - val_loss: 0.1004
Epoch 90/150
 - 35s - loss: 0.0433 - val_loss: 0.1206
Epoch 91/150
 - 35s - loss: 0.0475 - val_loss: 0.0975
Epoch 92/150
 - 35s - loss: 0.0436 - val_loss: 0.0767
Epoch 93/150
 - 35s - loss: 0.0428 - val_loss: 0.0825
Epoch 94/150
 - 35s - loss: 0.0423 - val_loss: 0.1094
Epoch 95/150
 - 35s - loss: 0.0427 - val_loss: 0.0863
Epoch 96/150
 - 35s - loss: 0.0414 - val_loss: 0.0822
Epoch 97/150
 - 35s - loss: 0.0409 - val_loss: 0.0887
Epoch 98/150
 - 35s - loss: 0.0410 - val_loss: 0.0862
Epoch 99/150
 - 35s - loss: 0.0406 - val_loss: 0.0953
Epoch 100/150
 - 35s - loss: 0.0405 - val_loss: 0.0804
Epoch 101/150
 - 35s - loss: 0.0402 - val_loss: 0.0956
Epoch 102/150
 - 35s - loss: 0.0403 - val_loss: 0.0897
Epoch 103/150
 - 35s - loss: 0.0402 - val_loss: 0.0842
Epoch 104/150
 - 35s - loss: 0.0412 - val_loss: 0.1215
Epoch 105/150
 - 35s - loss: 0.0584 - val_loss: 0.1535
Epoch 106/150
 - 35s - loss: 0.0477 - val_loss: 0.0889
Epoch 107/150
 - 35s - loss: 0.0426 - val_loss: 0.0834
Epoch 108/150
 - 35s - loss: 0.0412 - val_loss: 0.0815
Epoch 109/150
 - 35s - loss: 0.0418 - val_loss: 0.0822
Epoch 110/150
 - 35s - loss: 0.0407 - val_loss: 0.0825
Epoch 111/150
 - 35s - loss: 0.0400 - val_loss: 0.0926
Epoch 112/150
 - 35s - loss: 0.0408 - val_loss: 0.0974
Epoch 113/150
 - 35s - loss: 0.0400 - val_loss: 0.0796
Epoch 114/150
 - 35s - loss: 0.0394 - val_loss: 0.0793
Epoch 115/150
 - 35s - loss: 0.0397 - val_loss: 0.0907
Epoch 116/150
 - 35s - loss: 0.0389 - val_loss: 0.0874
Epoch 117/150
 - 35s - loss: 0.0387 - val_loss: 0.1052
Epoch 118/150
 - 35s - loss: 0.0411 - val_loss: 0.0910
Epoch 119/150
 - 35s - loss: 0.0392 - val_loss: 0.0834
Epoch 120/150
 - 35s - loss: 0.0387 - val_loss: 0.0881
Epoch 121/150
 - 35s - loss: 0.0392 - val_loss: 0.0903
Epoch 122/150
 - 35s - loss: 0.0381 - val_loss: 0.0849
Epoch 123/150
 - 35s - loss: 0.0380 - val_loss: 0.0926
Epoch 124/150
 - 35s - loss: 0.0374 - val_loss: 0.0889
Epoch 125/150
 - 35s - loss: 0.0378 - val_loss: 0.0884
Epoch 126/150
 - 35s - loss: 0.0375 - val_loss: 0.1020
Epoch 127/150
 - 35s - loss: 0.0372 - val_loss: 0.0988
Epoch 128/150
 - 35s - loss: 0.0369 - val_loss: 0.1001
Epoch 129/150
 - 35s - loss: 0.0372 - val_loss: 0.0919
Epoch 130/150
 - 35s - loss: 0.0370 - val_loss: 0.0893
Epoch 131/150
 - 35s - loss: 0.0368 - val_loss: 0.1114
Epoch 132/150
 - 35s - loss: 0.0366 - val_loss: 0.0923
Epoch 133/150
 - 35s - loss: 0.0370 - val_loss: 0.0980
Epoch 134/150
 - 35s - loss: 0.0367 - val_loss: 0.0911
Epoch 135/150
 - 35s - loss: 0.0363 - val_loss: 0.0975
Epoch 136/150
 - 35s - loss: 0.0363 - val_loss: 0.0928
Epoch 137/150
 - 35s - loss: 0.0361 - val_loss: 0.0871
Epoch 138/150
 - 35s - loss: 0.0381 - val_loss: 0.0966
Epoch 139/150
 - 35s - loss: 0.0367 - val_loss: 0.0927
Epoch 140/150
 - 35s - loss: 0.0362 - val_loss: 0.0903
Epoch 141/150
 - 35s - loss: 0.0361 - val_loss: 0.1112
Epoch 142/150
 - 35s - loss: 0.0358 - val_loss: 0.1010
Epoch 143/150
 - 35s - loss: 0.0355 - val_loss: 0.1016
Epoch 144/150
 - 35s - loss: 0.0351 - val_loss: 0.1042
Epoch 145/150
 - 35s - loss: 0.0349 - val_loss: 0.0972
Epoch 146/150
 - 35s - loss: 0.0348 - val_loss: 0.0981
Epoch 147/150
 - 35s - loss: 0.0351 - val_loss: 0.0954
Epoch 148/150
 - 35s - loss: 0.0347 - val_loss: 0.1163
Epoch 149/150
 - 35s - loss: 0.0344 - val_loss: 0.0937
Epoch 150/150
 - 35s - loss: 0.0350 - val_loss: 0.1049
Using TensorFlow backend.
